## Secrets belong in `.env.secrets` (never commit it).
# API_TOKEN=change-me
COQUI_TOS_AGREED=1
TTS_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
TTS_LANG=en
TTS_SPEAKER=default
WHISPER_MODEL=medium
HF_HOME=/root/.cache/huggingface
TORCH_HOME=/root/.cache/torch
TTS_HOME=/root/.local/share/tts
DIARIZATION_MODEL=pyannote/speaker-diarization
# Optional Hugging Face token for gated models (pyannote, etc.)
# HUGGINGFACE_TOKEN=change-me
# HF_TOKEN=change-me  # legacy name

# Secure auth secrets (generate strong random values for production)
# JWT_SECRET=change-me
# SESSION_SECRET=change-me
# CSRF_SECRET=change-me

# Optional admin bootstrap (created/updated at server startup)
# ADMIN_USERNAME=admin
# ADMIN_PASSWORD=change-me

# Cookies / CORS
# COOKIE_SECURE=1  # enable when behind HTTPS
# CORS_ORIGINS=https://example.com,https://other.example.com
# REDIS_URL=redis://redis:6379/0

# Offline / egress controls
# OFFLINE_MODE=1 forces no downloads/egress (must have caches populated)
OFFLINE_MODE=0
# ALLOW_EGRESS=0 hard-denies outbound connections (except localhost)
ALLOW_EGRESS=1
# ALLOW_HF_EGRESS=1 allows only *.huggingface.co egress when ALLOW_EGRESS=0
ALLOW_HF_EGRESS=0
# Optional override translation model (else Marian -> NLLB fallback)
# TRANSLATION_MODEL=Helsinki-NLP/opus-mt-ja-en
# Optional HF cache override
# TRANSFORMERS_CACHE=/root/.cache/huggingface/transformers

# Optional TTS cloning / voice selection
# If set, will attempt zero-shot clone from this WAV
# TTS_SPEAKER_WAV=/path/to/voice.wav
# Voice selection strategy (optional):
#   - clone: try speaker wav cloning, then preset fallback (default)
#   - preset: skip cloning, use preset selection
#   - single: force single narrator voice
# VOICE_MODE=clone
# Optional directory of stable reference WAVs:
#   - <VOICE_REF_DIR>/<speaker_id>.wav
#   - <VOICE_REF_DIR>/<speaker_id>/ref.wav
# VOICE_REF_DIR=/workspace/data/voices
# Optional persistent voice store (where the pipeline may cache reference wavs)
# VOICE_STORE=/workspace/data/voices
# Provider selection (optional): auto|xtts|basic|espeak
# TTS_PROVIDER=auto
# Voice presets directory and DB (used when cloning fails / unavailable)
VOICE_PRESET_DIR=/workspace/voices/presets
VOICE_DB=/workspace/voices/presets.json

# Character store encryption (required for persistence)
# Generate a 32-byte random key and base64-encode it.
# Example (bash): python -c "import os,base64; print(base64.b64encode(os.urandom(32)).decode())"
# CHAR_STORE_KEY=change-me
# Optional: read key from a mounted file
# CHAR_STORE_KEY_FILE=/app/secrets/char_store.key

# Retention policy (best-effort purges for old uploads/logs)
RETENTION_DAYS_INPUT=7
RETENTION_DAYS_LOGS=14

# Per-job retention policy (Feature B)
# - full: keep everything (default)
# - balanced: delete heavy intermediates (stems/chunks/segments/tmp/tracks)
# - minimal: keep final outputs + essential logs/manifests + small analysis/subs
CACHE_POLICY=full
# If >0, apply retention only to jobs older than N days (0 disables age gating)
RETENTION_DAYS=0

# Feature M: Optional offline LLM rewrite provider (OFF by default)
# Used only when TIMING_FIT=1 and REWRITE_PROVIDER=local_llm.
# Endpoint must be localhost-only.
REWRITE_PROVIDER=heuristic
# REWRITE_ENDPOINT=http://127.0.0.1:8080/completion
# REWRITE_MODEL=/models/my_local_llm
REWRITE_STRICT=1

# Storage guard + temp workdir cleanup
MIN_FREE_GB=10
WORK_STALE_MAX_HOURS=24

# Latency budgets (seconds) for "degraded" flag
BUDGET_TRANSCRIBE_SEC=600
BUDGET_TTS_SEC=900
BUDGET_MUX_SEC=120

# Job limits / quotas
MAX_VIDEO_MIN=120
MAX_UPLOAD_MB=2048
MAX_CONCURRENT=2
DAILY_PROCESSING_MINUTES=240

# Job watchdog timeouts (seconds)
WATCHDOG_AUDIO_S=600
WATCHDOG_DIARIZE_S=1200
WATCHDOG_WHISPER_S=2700
WATCHDOG_TRANSLATE_S=600
WATCHDOG_TTS_S=1800
WATCHDOG_MIX_S=1200

# Model manager prewarm + GPU allocator thresholds
# PREWARM_WHISPER=large-v3,medium,small
# PREWARM_TTS=tts_models/multilingual/multi-dataset/xtts_v2
MODEL_CACHE_MAX=3
GPU_UTIL_MAX=0.85
GPU_MEM_MAX_RATIO=0.90

# Runtime scheduler limits (in-proc)
MAX_CONCURRENCY_GLOBAL=2
MAX_CONCURRENCY_TRANSCRIBE=1
MAX_CONCURRENCY_TTS=1
BACKPRESSURE_Q_MAX=6
# Set to -1 to disable backpressure mode degrade/delay
# BACKPRESSURE_Q_MAX=-1

# Retry / circuit breaker tuning
RETRY_MAX=3
RETRY_BASE_SEC=0.5
RETRY_CAP_SEC=8.0
CB_FAIL_THRESHOLD=5
CB_COOLDOWN_SEC=60

# Optional: basic fallback TTS model name (Coqui, single-speaker)
# TTS_BASIC_MODEL=tts_models/en/ljspeech/tacotron2-DDC

# Expressive speech controls (best-effort; applied after synthesis)
# EMOTION_MODE=off  # off|auto|tags
# SPEECH_RATE=1.0
# PITCH=1.0
# ENERGY=1.0

# ASR metadata (optional; model support dependent)
# WHISPER_WORD_TIMESTAMPS=0

# Job submission idempotency
IDEMPOTENCY_TTL_SEC=86400

# Cross-job cache directory (defaults to Output/cache)
# ANIME_V2_CACHE_DIR=/app/Output/cache

# Ops: backup destination (optional, requires aws cli inside container/host)
# BACKUP_S3_URL=s3://your-bucket/anime-v2-backups/

# Deploy: public HTTPS / tunnel
# DOMAIN=anime.example.com
# CADDY_EMAIL=you@example.com
# CLOUDFLARE_TUNNEL_TOKEN=change-me

# Notifications (optional; private self-hosted ntfy)
# NTFY_ENABLED=0
# NTFY_BASE_URL=http://127.0.0.1:8081
# NTFY_TOPIC=change-me-random-topic
# PUBLIC_BASE_URL=http://127.0.0.1:8000
# Secrets belong in `.env.secrets`:
# NTFY_AUTH=token:change-me
