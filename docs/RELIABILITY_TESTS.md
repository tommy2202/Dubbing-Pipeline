## Reliability tests (P1)

These lightweight scripts validate the P1 reliability scenarios. They avoid GPU use and run on small synthetic media (1–2 seconds).

### Prerequisites
- `ffmpeg` and `ffprobe` on `PATH`
- Python dependencies installed (FastAPI stack for API-based tests)

### Quick gate (P1)

```bash
python scripts/p1_gate.py
```

The gate will **skip gracefully** if optional dependencies (e.g. FastAPI, ffmpeg) are missing.

### Individual scripts

```bash
# Two users submit simultaneously
python scripts/e2e_two_users_submit.py

# Upload interrupted + resumed
python scripts/e2e_upload_resume.py

# Cancel mid-run
python scripts/e2e_cancel_midrun.py

# Restart worker mid-run
python scripts/e2e_restart_worker_midrun.py

# Redis down -> fallback -> Redis back
python scripts/e2e_redis_fallback.py
```

### Notes
- All scripts use `device=cpu` and do not load GPU models.
- Some scripts rely on FastAPI’s TestClient; missing FastAPI is treated as a **skip**.
- The Redis fallback test does **not** require a live Redis instance; it simulates health transitions.
# Reliability tests & runbook

This document describes **real-world failure scenarios** and the corresponding **end-to-end reliability tests** included in this repository.

## Goals

- Catch failures early (before a user loses time on a long job).
- Use **tiny synthetic samples** (generated by ffmpeg) where possible.
- Keep default tests **lite** (no huge model downloads required).
- Produce **actionable, operator-friendly output** (what failed + likely fix).

## Quickstart

Run these from the repo root:

```bash
python3 scripts/e2e_smoke_cli.py
python3 scripts/e2e_smoke_web.py
python3 scripts/e2e_ffmpeg_cases.py
python3 scripts/e2e_upload_resume.py
python3 scripts/e2e_gpu_sanity.py
python3 scripts/e2e_concurrency_two_users.py
python3 scripts/e2e_job_recovery.py
python3 scripts/collect_diagnostics.py
```

If something fails, start with:

```bash
python3 scripts/collect_diagnostics.py
```

## Scenario: ffmpeg edge cases

**Why it fails in the real world**
- Variable frame rate (VFR) recordings, screen-captures, and mobile recordings can expose timestamp / duration bugs.
- Videos with **no audio** should be rejected clearly (rather than crashing later).
- Some codecs/containers are missing on minimal ffmpeg builds.

**Test**
- `scripts/e2e_ffmpeg_cases.py`

**Pass criteria**
- VFR sample: `ffprobe` succeeds, audio extraction works.
- No-audio sample: system detects missing audio and produces a **clear** error message.
- Optional odd codec sample: runs if the encoder is available; otherwise the test **skips** cleanly with a reason.

## Scenario: CUDA / driver mismatch (GPU sanity)

**Why it fails in the real world**
- `torch` installed with the wrong CUDA build for the installed NVIDIA driver.
- CUDA runtime libraries missing inside container.
- GPU visible to the OS (`nvidia-smi`) but not to PyTorch (`torch.cuda.is_available() == False`).

**Test**
- `scripts/e2e_gpu_sanity.py`

**Pass criteria**
- If no GPU is available: test exits **SKIP** (not failure).
- If GPU is available:
  - `nvidia-smi` works (host driver sane)
  - `torch.cuda.is_available()` works (runtime sane)
  - Script prints versions and a small GPU allocation succeeds.
- On mismatch: test fails with **fix steps** (what to reinstall / what to check).

## Scenario: model cache / download failures (lite path)

**Why it fails in the real world**
- Cache directory is not writable (Docker volume permissions).
- Offline mode is enabled but models are missing.
- Network egress blocked (firewall) causes downloads to hang/fail.

**Tests**
- `scripts/e2e_smoke_cli.py` (lite path: validates cache + config, no heavy downloads)
- `scripts/collect_diagnostics.py` (reports cache locations + permissions)

**Pass criteria**
- Cache/model directories exist or can be created.
- If optional model deps are missing, output explains how to install/enable them.
- No long hangs (tests have timeouts).

## Scenario: long-running job resilience (operator checklist)

**Why it fails in the real world**
- Power loss / restart mid-job.
- Disk fills up during output generation.
- Worker crash while a job is running.

**Tests**
- `scripts/e2e_job_recovery.py` (automated, lightweight)
- Optional manual: restart the server during a real job

**Pass criteria**
- `e2e_job_recovery.py` reports OK and shows queued recovery state.
- Manual: job returns to **QUEUED** after restart and logs “Recovered after restart”.
  - Output dir remains writable and has free space.

**Pass criteria**
- No “stuck RUNNING forever” after restart.
- Job is safely re-queued or marked failed with a clear reason.

## Scenario: resumable uploads under poor network

**Why it fails in the real world**
- Mobile networks drop connections mid-upload.
- Clients retry chunks; server must be **idempotent** for duplicate chunk uploads.

**Test**
- `scripts/e2e_upload_resume.py`
  - Set `SIMULATE_NETWORK_LOSS=1` to enable flaky upload retries.

**Pass criteria**
- Upload session can be resumed after interruption (new client/session).
- Re-sending a previously uploaded chunk is **idempotent** (server accepts and does not double-count bytes).
- Finalization succeeds with a correct SHA256.

## Scenario: multi-user concurrency sanity

**Why it fails in the real world**
- Dispatch logic can ignore global caps or user limits under load.
- Two users submitting at the same time can expose scheduler race bugs.

**Test**
- `scripts/e2e_concurrency_two_users.py`

**Pass criteria**
- Only one job dispatches at a time when `MAX_CONCURRENCY_GLOBAL=1`.
- Second job dispatches only after the first is marked done.

## CI integration (nightly)

These tests are wired as an **optional nightly job**:
- GPU checks run only when the runner actually has a GPU; otherwise they skip.
- The default nightly is “lite” and avoids large model downloads.

